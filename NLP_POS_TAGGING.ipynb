{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPikA+Q/68J8mHV3jKyx1kT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SwethaB04/NLP/blob/main/NLP_POS_TAGGING.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwuZm-JWsgbC",
        "outputId": "fb2948b9-02f8-496b-d9e6-94028908147d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "para = \"\"\" With the ability to quantify the number of paragraphs you want, you have complete control over the length and quantity of the generated content. Whether you require a single paragraph for a social media post or an extensive piece for an article, our Random Paragraph Generator is at your service.\n",
        "\n",
        "The paragraphs generated by our tool cover a wide range of topics, making it ideal for various purposes. From creative writing and academic projects to professional content creation, our generator delivers high-quality paragraphs that cater to your preferences \"\"\""
      ],
      "metadata": {
        "id": "pGplNMi4shBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = nltk.sent_tokenize(para)\n",
        "sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7yZbnajs94T",
        "outputId": "9b6e43c7-74f4-4989-e5f7-d57d99ca04f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' With the ability to quantify the number of paragraphs you want, you have complete control over the length and quantity of the generated content.',\n",
              " 'Whether you require a single paragraph for a social media post or an extensive piece for an article, our Random Paragraph Generator is at your service.',\n",
              " 'The paragraphs generated by our tool cover a wide range of topics, making it ideal for various purposes.',\n",
              " 'From creative writing and academic projects to professional content creation, our generator delivers high-quality paragraphs that cater to your preferences']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = nltk.word_tokenize(para)\n",
        "words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_qwoNEdtEuL",
        "outputId": "d1bce71e-426f-4be6-eb45-dc3ade628378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['With',\n",
              " 'the',\n",
              " 'ability',\n",
              " 'to',\n",
              " 'quantify',\n",
              " 'the',\n",
              " 'number',\n",
              " 'of',\n",
              " 'paragraphs',\n",
              " 'you',\n",
              " 'want',\n",
              " ',',\n",
              " 'you',\n",
              " 'have',\n",
              " 'complete',\n",
              " 'control',\n",
              " 'over',\n",
              " 'the',\n",
              " 'length',\n",
              " 'and',\n",
              " 'quantity',\n",
              " 'of',\n",
              " 'the',\n",
              " 'generated',\n",
              " 'content',\n",
              " '.',\n",
              " 'Whether',\n",
              " 'you',\n",
              " 'require',\n",
              " 'a',\n",
              " 'single',\n",
              " 'paragraph',\n",
              " 'for',\n",
              " 'a',\n",
              " 'social',\n",
              " 'media',\n",
              " 'post',\n",
              " 'or',\n",
              " 'an',\n",
              " 'extensive',\n",
              " 'piece',\n",
              " 'for',\n",
              " 'an',\n",
              " 'article',\n",
              " ',',\n",
              " 'our',\n",
              " 'Random',\n",
              " 'Paragraph',\n",
              " 'Generator',\n",
              " 'is',\n",
              " 'at',\n",
              " 'your',\n",
              " 'service',\n",
              " '.',\n",
              " 'The',\n",
              " 'paragraphs',\n",
              " 'generated',\n",
              " 'by',\n",
              " 'our',\n",
              " 'tool',\n",
              " 'cover',\n",
              " 'a',\n",
              " 'wide',\n",
              " 'range',\n",
              " 'of',\n",
              " 'topics',\n",
              " ',',\n",
              " 'making',\n",
              " 'it',\n",
              " 'ideal',\n",
              " 'for',\n",
              " 'various',\n",
              " 'purposes',\n",
              " '.',\n",
              " 'From',\n",
              " 'creative',\n",
              " 'writing',\n",
              " 'and',\n",
              " 'academic',\n",
              " 'projects',\n",
              " 'to',\n",
              " 'professional',\n",
              " 'content',\n",
              " 'creation',\n",
              " ',',\n",
              " 'our',\n",
              " 'generator',\n",
              " 'delivers',\n",
              " 'high-quality',\n",
              " 'paragraphs',\n",
              " 'that',\n",
              " 'cater',\n",
              " 'to',\n",
              " 'your',\n",
              " 'preferences']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stemming"
      ],
      "metadata": {
        "id": "7t3E63qqtR4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWZf3aPMtNHN",
        "outputId": "0074cea8-989c-4cf5-e05d-abb57ec41c8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "stopwords.fileids()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1Q8SoZVtVui",
        "outputId": "b63e7b13-79c4-4b21-9607-c4a07990983c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['arabic',\n",
              " 'azerbaijani',\n",
              " 'basque',\n",
              " 'bengali',\n",
              " 'catalan',\n",
              " 'chinese',\n",
              " 'danish',\n",
              " 'dutch',\n",
              " 'english',\n",
              " 'finnish',\n",
              " 'french',\n",
              " 'german',\n",
              " 'greek',\n",
              " 'hebrew',\n",
              " 'hinglish',\n",
              " 'hungarian',\n",
              " 'indonesian',\n",
              " 'italian',\n",
              " 'kazakh',\n",
              " 'nepali',\n",
              " 'norwegian',\n",
              " 'portuguese',\n",
              " 'romanian',\n",
              " 'russian',\n",
              " 'slovene',\n",
              " 'spanish',\n",
              " 'swedish',\n",
              " 'tajik',\n",
              " 'turkish']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()\n",
        "for i in range(len(sentence)):\n",
        "  words = nltk.word_tokenize(sentence[i])\n",
        "  words = [stemmer.stem(word) for word in words if word not in set(stopwords.words('english'))]\n",
        "  sentence[i] = ' '.join(words)\n",
        "\n",
        "words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onQFtXtQtann",
        "outputId": "2727420c-0760-47da-cb16-b4da568932b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['creativ',\n",
              " 'write',\n",
              " 'academ',\n",
              " 'project',\n",
              " 'profess',\n",
              " 'content',\n",
              " 'creation',\n",
              " ',',\n",
              " 'gener',\n",
              " 'deliv',\n",
              " 'high-qual',\n",
              " 'paragraph',\n",
              " 'cater',\n",
              " 'prefer']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatization"
      ],
      "metadata": {
        "id": "klfkvNm-uTJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "sentence = nltk.sent_tokenize(para)\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "4JepUgoNtnI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "for i in range(len(sentence)):\n",
        "  words = nltk.word_tokenize(sentence[i])\n",
        "  words = [lemmatizer.lemmatize(word) for word in words if word not in set(stopwords.words('english'))]\n",
        "  sentence[i] = ' ' .join(words)\n",
        "words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjnKBR_6uhf3",
        "outputId": "cc49467e-933d-49cf-b33d-371bad512202"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['From',\n",
              " 'creative',\n",
              " 'writing',\n",
              " 'academic',\n",
              " 'project',\n",
              " 'professional',\n",
              " 'content',\n",
              " 'creation',\n",
              " ',',\n",
              " 'generator',\n",
              " 'delivers',\n",
              " 'high-quality',\n",
              " 'paragraph',\n",
              " 'cater',\n",
              " 'preference']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokenizer = nltk.word_tokenize(para)"
      ],
      "metadata": {
        "id": "mP9cIE1BuqJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wZNVQ7tuuL6",
        "outputId": "43d4b0f3-b262-4e0f-8e72-f75328bf3847"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PARTS OF SPEECH (POS)"
      ],
      "metadata": {
        "id": "1G5A-y9juy9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pos = nltk.pos_tag(word_tokenizer)\n",
        "pos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRBbslXwuxye",
        "outputId": "dde7129b-f1f5-49b5-e3c5-e9db4242f0f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('With', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('ability', 'NN'),\n",
              " ('to', 'TO'),\n",
              " ('quantify', 'VB'),\n",
              " ('the', 'DT'),\n",
              " ('number', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('paragraphs', 'NN'),\n",
              " ('you', 'PRP'),\n",
              " ('want', 'VBP'),\n",
              " (',', ','),\n",
              " ('you', 'PRP'),\n",
              " ('have', 'VBP'),\n",
              " ('complete', 'JJ'),\n",
              " ('control', 'NN'),\n",
              " ('over', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('length', 'NN'),\n",
              " ('and', 'CC'),\n",
              " ('quantity', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('generated', 'JJ'),\n",
              " ('content', 'NN'),\n",
              " ('.', '.'),\n",
              " ('Whether', 'IN'),\n",
              " ('you', 'PRP'),\n",
              " ('require', 'VBP'),\n",
              " ('a', 'DT'),\n",
              " ('single', 'JJ'),\n",
              " ('paragraph', 'NN'),\n",
              " ('for', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('social', 'JJ'),\n",
              " ('media', 'NNS'),\n",
              " ('post', 'NN'),\n",
              " ('or', 'CC'),\n",
              " ('an', 'DT'),\n",
              " ('extensive', 'JJ'),\n",
              " ('piece', 'NN'),\n",
              " ('for', 'IN'),\n",
              " ('an', 'DT'),\n",
              " ('article', 'NN'),\n",
              " (',', ','),\n",
              " ('our', 'PRP$'),\n",
              " ('Random', 'NNP'),\n",
              " ('Paragraph', 'NNP'),\n",
              " ('Generator', 'NNP'),\n",
              " ('is', 'VBZ'),\n",
              " ('at', 'IN'),\n",
              " ('your', 'PRP$'),\n",
              " ('service', 'NN'),\n",
              " ('.', '.'),\n",
              " ('The', 'DT'),\n",
              " ('paragraphs', 'NN'),\n",
              " ('generated', 'VBN'),\n",
              " ('by', 'IN'),\n",
              " ('our', 'PRP$'),\n",
              " ('tool', 'NN'),\n",
              " ('cover', 'VB'),\n",
              " ('a', 'DT'),\n",
              " ('wide', 'JJ'),\n",
              " ('range', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('topics', 'NNS'),\n",
              " (',', ','),\n",
              " ('making', 'VBG'),\n",
              " ('it', 'PRP'),\n",
              " ('ideal', 'VB'),\n",
              " ('for', 'IN'),\n",
              " ('various', 'JJ'),\n",
              " ('purposes', 'NNS'),\n",
              " ('.', '.'),\n",
              " ('From', 'IN'),\n",
              " ('creative', 'JJ'),\n",
              " ('writing', 'NN'),\n",
              " ('and', 'CC'),\n",
              " ('academic', 'JJ'),\n",
              " ('projects', 'NNS'),\n",
              " ('to', 'TO'),\n",
              " ('professional', 'JJ'),\n",
              " ('content', 'NN'),\n",
              " ('creation', 'NN'),\n",
              " (',', ','),\n",
              " ('our', 'PRP$'),\n",
              " ('generator', 'NN'),\n",
              " ('delivers', 'VBZ'),\n",
              " ('high-quality', 'NN'),\n",
              " ('paragraphs', 'NN'),\n",
              " ('that', 'WDT'),\n",
              " ('cater', 'NN'),\n",
              " ('to', 'TO'),\n",
              " ('your', 'PRP$'),\n",
              " ('preferences', 'NNS')]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, len(pos)):\n",
        "  if(pos[i][1]=='NNS'):\n",
        "    print(pos[i][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pdnAnMMu1Wr",
        "outputId": "3be83c4c-e44c-4a75-b501-738352a8788d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "media\n",
            "topics\n",
            "purposes\n",
            "projects\n",
            "preferences\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('tagsets')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1nbUHUCu7zr",
        "outputId": "e29bc8d7-77ba-49d7-ad91-e9174e14e52e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]   Unzipping help/tagsets.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.help.upenn_tagset('NNS')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmOAW_oQu-GY",
        "outputId": "2346c6ef-58d6-44de-af04-ff72cc80ecbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NNS: noun, common, plural\n",
            "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
            "    divestitures storehouses designs clubs fragrances averages\n",
            "    subjectivists apprehensions muses factory-jobs ...\n"
          ]
        }
      ]
    }
  ]
}